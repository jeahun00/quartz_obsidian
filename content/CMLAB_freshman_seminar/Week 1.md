# Sung Kim ëª¨ë‘ì˜ ë”¥ëŸ¬ë‹
https://hunkim.github.io/ml/

- [x] ë¨¸ì‹ ëŸ¬ë‹ì˜ ê°œë…ê³¼ ìš©ì–´ âœ… 2023-11-07
- [x] Linear Regression ì˜ ê°œë… âœ… 2023-11-07
- [x] Linear Regression costí•¨ìˆ˜ ìµœì†Œí™” âœ… 2023-11-07
- [x] ì—¬ëŸ¬ê°œì˜ ì…ë ¥(feature)ì˜ Linear Regression âœ… 2023-11-07
- [x] Logistic (Regression) Classification âœ… 2023-11-08
- [x] Softmax Regression (Multinomial Logistic Regression) âœ… 2023-11-09
- [x] MLì˜ ì‹¤ìš©ê³¼ ëª‡ê°€ì§€ íŒ âœ… 2023-11-09
- [x] lab7 metal gpu ëŒë¦´ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸ + ppt ë§ˆë¬´ë¦¬ ğŸ“… 2023-11-09 âœ… 2023-11-13
# Stanford CS231n

$W := W - \alpha \frac{\partial}{\partial W} cost(W)$ 
$W := W - \alpha \frac{1}{m} \sum_{i=1}^{m} (Wx^{(i)}-y_{(i)})x^{(i)}$ 

$$
\begin{align*}\\
\underset{x\_train}{\\
\underbrace{
\begin{bmatrix}
{73}&{80}&{75}\\
{93}&{88}&{93}\\
{89}&{91}&{80}\\
{96}&{66}&{70}\\
{73}&{66}&{70}
\end{bmatrix}}}
\cdot
\underset{W}{\\
\underbrace{
\begin{bmatrix}
{W_1}\\
{W_2}\\
{W_3}\\
\end{bmatrix}}}
=
\underset{y\_train}{\\
\underbrace{
\begin{bmatrix}
{152}\\
{185}\\
{180}\\
{196}\\
{142}\\
\end{bmatrix}}}
\end{align*}
$$